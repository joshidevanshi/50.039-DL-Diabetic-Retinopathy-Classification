{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58nKvT57kaUK",
        "outputId": "9b084976-8b09-499a-8e78-95455ffd12d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchviz\n",
            "  Downloading torchviz-0.0.2.tar.gz (4.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchviz) (2.2.1+cu121)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from torchviz) (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->torchviz)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->torchviz)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->torchviz)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->torchviz)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->torchviz)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->torchviz)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->torchviz)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->torchviz)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->torchviz)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch->torchviz)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->torchviz)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->torchviz)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchviz) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchviz) (1.3.0)\n",
            "Building wheels for collected packages: torchviz\n",
            "  Building wheel for torchviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchviz: filename=torchviz-0.0.2-py3-none-any.whl size=4132 sha256=f527a5e857a3815f1ea41cba6cdc8c5cb5e203f997d69cffd6d1a4eabc3a73a5\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/97/88/a02973217949e0db0c9f4346d154085f4725f99c4f15a87094\n",
            "Successfully built torchviz\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchviz\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 torchviz-0.0.2\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from io import BytesIO\n",
        "from zipfile import ZipFile\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "from torch import optim\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "import copy\n",
        "from tqdm.notebook import tqdm\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report\n",
        "!pip install torchviz\n",
        "from torchviz import make_dot\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9Bg1Sjz801Z"
      },
      "source": [
        "## Download the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4G0cvY55nnYv"
      },
      "outputs": [],
      "source": [
        "#Download the Dataset\n",
        "\n",
        "dataset_link = 'https://universe.roboflow.com/ds/34oBZCp0Y9?key=M2AxU6iuig'\n",
        "response = requests.get(dataset_link)\n",
        "zip_file = ZipFile(BytesIO(response.content))\n",
        "\n",
        "extracted_folder = '/dataset'\n",
        "zip_file.extractall(extracted_folder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6ZroeX09LQf"
      },
      "source": [
        "## Pre-processing Dataset\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4XBiQYENuWQi"
      },
      "outputs": [],
      "source": [
        "transform_train = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize((224,224)),\n",
        "        # using such random flips, helps to increase variability in your training data, which can prevent overfitting and improve the model's ability to generalize to unseen data\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.RandomVerticalFlip(p=0.5),\n",
        "        transforms.RandomRotation(30),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean = [0.485, 0.456, 0.406],std = [0.229, 0.224, 0.225])\n",
        "   ]\n",
        ")\n",
        "\n",
        "transform_test = transforms.Compose(\n",
        "    [\n",
        "         #all the images are currently 224 pixels but we can rezie later according to model accuracy to see if it makes any difference\n",
        "        transforms.Resize((224,224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean = [0.485, 0.456, 0.406],std = [0.229, 0.224, 0.225])\n",
        "   ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L19Jm8Hyt3Wu",
        "outputId": "495acc0c-03c8-4c6d-f99f-e94059b4ce99"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Compose(\n",
              "    Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
              "    ToTensor()\n",
              "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Define object of the Train, Validation, and Test dataset.\n",
        "\n",
        "train_dataset = torchvision.datasets.ImageFolder(\"/dataset/train\", transform=transform_train)\n",
        "train_dataset.transform\n",
        "\n",
        "val_dataset = torchvision.datasets.ImageFolder(\"/dataset/valid\", transform=transform_test)\n",
        "val_dataset.transform\n",
        "\n",
        "test_dataset = torchvision.datasets.ImageFolder(\"/dataset/test\", transform=transform_test)\n",
        "test_dataset.transform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fc_eFNIaA0ap"
      },
      "source": [
        "## Creating DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "CUybSc9EzNa6"
      },
      "outputs": [],
      "source": [
        "# train set has 2076 images so can use greater batch size but valid and test have 531 and 231 so must use smaller batch size or there will be overfitting\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = 200, shuffle = True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size = 64, shuffle = True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = 64, shuffle = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2WKOcbSz5XB",
        "outputId": "fe6cddef-d067-404b-9abb-6632ea539b7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data:\n",
            "Shape of X : torch.Size([200, 3, 224, 224])\n",
            "Shape of y: torch.Size([200]) torch.int64\n",
            "\n",
            "Validation data:\n",
            "Shape of X : torch.Size([64, 3, 224, 224])\n",
            "Shape of y: torch.Size([64]) torch.int64\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Print shape of Dataset\n",
        "for key, value in {'Training data': train_loader, \"Validation data\": val_loader}.items():\n",
        "    for X, y in value:\n",
        "        print(f\"{key}:\")\n",
        "        print(f\"Shape of X : {X.shape}\")\n",
        "        print(f\"Shape of y: {y.shape} {y.dtype}\\n\")\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4M386IZA93v"
      },
      "source": [
        "## Model Architectures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "kNSUpsSYezTM"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Define a basic residual block\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.stride = stride\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out += self.shortcut(residual)\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "# Define the ResNet model\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, params):\n",
        "        super(ResNet, self).__init__()\n",
        "        Cin, Hin, Win = params[\"shape_in\"]\n",
        "        init_f = params[\"initial_filters\"]\n",
        "        num_fc1 = params[\"num_fc1\"]\n",
        "        num_classes = params[\"num_classes\"]\n",
        "        self.dropout_rate = params[\"dropout_rate\"]\n",
        "\n",
        "        # Initial convolutional layer\n",
        "        self.conv1 = nn.Conv2d(Cin, init_f, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(init_f)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        # Residual blocks\n",
        "        self.layer1 = self.make_layer(init_f, init_f, 2)\n",
        "        self.layer2 = self.make_layer(init_f, 2*init_f, 2, stride=2)\n",
        "        self.layer3 = self.make_layer(2*init_f, 4*init_f, 2, stride=2)\n",
        "        self.layer4 = self.make_layer(4*init_f, 8*init_f, 2, stride=2)\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc1 = nn.Linear(8*init_f, num_fc1)\n",
        "        self.fc2 = nn.Linear(num_fc1, num_classes)\n",
        "\n",
        "    def make_layer(self, in_channels, out_channels, blocks, stride=1):\n",
        "        layers = []\n",
        "        layers.append(ResidualBlock(in_channels, out_channels, stride))\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(ResidualBlock(out_channels, out_channels))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.avg_pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, self.dropout_rate)\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJABv7kzBdWS"
      },
      "source": [
        "## Instantiate Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12IG6ruG5V43"
      },
      "outputs": [],
      "source": [
        "params_model={\n",
        "        \"shape_in\": (3,224,224),\n",
        "        \"initial_filters\": 8,\n",
        "        \"num_fc1\": 100,\n",
        "        \"dropout_rate\": 0.15,\n",
        "        \"num_classes\": 5}\n",
        "\n",
        "ResNet_model = ResNet(params_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGctlFGe7ISV"
      },
      "outputs": [],
      "source": [
        "# define computation hardware approach (GPU/CPU)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "ResNet_model = ResNet_model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09gytqWXBlOE"
      },
      "source": [
        "## Visualise Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8BKRCU4LXM4",
        "outputId": "7c5b32cd-40d4-448f-ae20-9bb9287016f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1          [-1, 8, 224, 224]             216\n",
            "       BatchNorm2d-2          [-1, 8, 224, 224]              16\n",
            "              ReLU-3          [-1, 8, 224, 224]               0\n",
            "            Conv2d-4          [-1, 8, 224, 224]             576\n",
            "       BatchNorm2d-5          [-1, 8, 224, 224]              16\n",
            "              ReLU-6          [-1, 8, 224, 224]               0\n",
            "            Conv2d-7          [-1, 8, 224, 224]             576\n",
            "       BatchNorm2d-8          [-1, 8, 224, 224]              16\n",
            "              ReLU-9          [-1, 8, 224, 224]               0\n",
            "    ResidualBlock-10          [-1, 8, 224, 224]               0\n",
            "           Conv2d-11          [-1, 8, 224, 224]             576\n",
            "      BatchNorm2d-12          [-1, 8, 224, 224]              16\n",
            "             ReLU-13          [-1, 8, 224, 224]               0\n",
            "           Conv2d-14          [-1, 8, 224, 224]             576\n",
            "      BatchNorm2d-15          [-1, 8, 224, 224]              16\n",
            "             ReLU-16          [-1, 8, 224, 224]               0\n",
            "    ResidualBlock-17          [-1, 8, 224, 224]               0\n",
            "           Conv2d-18         [-1, 16, 112, 112]           1,152\n",
            "      BatchNorm2d-19         [-1, 16, 112, 112]              32\n",
            "             ReLU-20         [-1, 16, 112, 112]               0\n",
            "           Conv2d-21         [-1, 16, 112, 112]           2,304\n",
            "      BatchNorm2d-22         [-1, 16, 112, 112]              32\n",
            "           Conv2d-23         [-1, 16, 112, 112]             128\n",
            "      BatchNorm2d-24         [-1, 16, 112, 112]              32\n",
            "             ReLU-25         [-1, 16, 112, 112]               0\n",
            "    ResidualBlock-26         [-1, 16, 112, 112]               0\n",
            "           Conv2d-27         [-1, 16, 112, 112]           2,304\n",
            "      BatchNorm2d-28         [-1, 16, 112, 112]              32\n",
            "             ReLU-29         [-1, 16, 112, 112]               0\n",
            "           Conv2d-30         [-1, 16, 112, 112]           2,304\n",
            "      BatchNorm2d-31         [-1, 16, 112, 112]              32\n",
            "             ReLU-32         [-1, 16, 112, 112]               0\n",
            "    ResidualBlock-33         [-1, 16, 112, 112]               0\n",
            "           Conv2d-34           [-1, 32, 56, 56]           4,608\n",
            "      BatchNorm2d-35           [-1, 32, 56, 56]              64\n",
            "             ReLU-36           [-1, 32, 56, 56]               0\n",
            "           Conv2d-37           [-1, 32, 56, 56]           9,216\n",
            "      BatchNorm2d-38           [-1, 32, 56, 56]              64\n",
            "           Conv2d-39           [-1, 32, 56, 56]             512\n",
            "      BatchNorm2d-40           [-1, 32, 56, 56]              64\n",
            "             ReLU-41           [-1, 32, 56, 56]               0\n",
            "    ResidualBlock-42           [-1, 32, 56, 56]               0\n",
            "           Conv2d-43           [-1, 32, 56, 56]           9,216\n",
            "      BatchNorm2d-44           [-1, 32, 56, 56]              64\n",
            "             ReLU-45           [-1, 32, 56, 56]               0\n",
            "           Conv2d-46           [-1, 32, 56, 56]           9,216\n",
            "      BatchNorm2d-47           [-1, 32, 56, 56]              64\n",
            "             ReLU-48           [-1, 32, 56, 56]               0\n",
            "    ResidualBlock-49           [-1, 32, 56, 56]               0\n",
            "           Conv2d-50           [-1, 64, 28, 28]          18,432\n",
            "      BatchNorm2d-51           [-1, 64, 28, 28]             128\n",
            "             ReLU-52           [-1, 64, 28, 28]               0\n",
            "           Conv2d-53           [-1, 64, 28, 28]          36,864\n",
            "      BatchNorm2d-54           [-1, 64, 28, 28]             128\n",
            "           Conv2d-55           [-1, 64, 28, 28]           2,048\n",
            "      BatchNorm2d-56           [-1, 64, 28, 28]             128\n",
            "             ReLU-57           [-1, 64, 28, 28]               0\n",
            "    ResidualBlock-58           [-1, 64, 28, 28]               0\n",
            "           Conv2d-59           [-1, 64, 28, 28]          36,864\n",
            "      BatchNorm2d-60           [-1, 64, 28, 28]             128\n",
            "             ReLU-61           [-1, 64, 28, 28]               0\n",
            "           Conv2d-62           [-1, 64, 28, 28]          36,864\n",
            "      BatchNorm2d-63           [-1, 64, 28, 28]             128\n",
            "             ReLU-64           [-1, 64, 28, 28]               0\n",
            "    ResidualBlock-65           [-1, 64, 28, 28]               0\n",
            "AdaptiveAvgPool2d-66             [-1, 64, 1, 1]               0\n",
            "           Linear-67                  [-1, 100]           6,500\n",
            "           Linear-68                    [-1, 5]             505\n",
            "================================================================\n",
            "Total params: 182,757\n",
            "Trainable params: 182,757\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 94.94\n",
            "Params size (MB): 0.70\n",
            "Estimated Total Size (MB): 96.21\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Model Summary\n",
        "summary(ResNet_model, input_size=(3, 224, 224),device=device.type)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "IQzMQZw2BwOv",
        "outputId": "44388108-15b7-4094-ca01-dd19232ddee6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ResNet_model_visualization.pdf'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "#visualise the model in an image form\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "ResNet_model.to(device)\n",
        "\n",
        "input_tensor = torch.randn(1, 3, 224, 224, device=device)\n",
        "\n",
        "dot = make_dot(ResNet_model(input_tensor), params=dict(ResNet_model.named_parameters()))\n",
        "\n",
        "dot.render(\"ResNet_model_visualization\", format=\"pdf\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7jm6maADQwB"
      },
      "source": [
        "## Define Optimizer and Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "js3SWZD7LiLF"
      },
      "outputs": [],
      "source": [
        "loss_func = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qvZP4vRL0ea",
        "outputId": "bc94cc96-1c19-4e84-cb8f-531e81b8ee2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
          ]
        }
      ],
      "source": [
        "opt = optim.AdamW(ResNet_model.parameters(), lr=0.001)\n",
        "\n",
        "lr_scheduler = ReduceLROnPlateau(opt, mode='min',factor=0.5, patience=20,verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZDYGwDYDr2n"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4MqDieV7de3m"
      },
      "outputs": [],
      "source": [
        "# Function to get the learning rate\n",
        "def get_lr(opt):\n",
        "    for param_group in opt.param_groups:\n",
        "        return param_group['lr']\n",
        "\n",
        "# Function to compute the loss value per batch of data\n",
        "def loss_batch(loss_func, output, target, opt=None):\n",
        "\n",
        "    loss = loss_func(output, target) # get loss\n",
        "    pred = output.argmax(dim=1, keepdim=True) # Get Output Class\n",
        "    metric_b=pred.eq(target.view_as(pred)).sum().item() # get performance metric\n",
        "\n",
        "    if opt is not None:\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "    return loss.item(), metric_b\n",
        "\n",
        "# Compute the loss value & performance metric for epoch\n",
        "def loss_epoch(model,loss_func,dataset_dl,opt=None):\n",
        "\n",
        "    run_loss=0.0\n",
        "    t_metric=0.0\n",
        "    len_data=len(dataset_dl.dataset)\n",
        "\n",
        "    for xb, yb in dataset_dl:\n",
        "        xb=xb.to(device)\n",
        "        yb=yb.to(device)\n",
        "        output=model(xb)\n",
        "        loss_b,metric_b=loss_batch(loss_func, output, yb, opt)\n",
        "        run_loss+=loss_b\n",
        "\n",
        "        if metric_b is not None:\n",
        "            t_metric+=metric_b\n",
        "\n",
        "    loss=run_loss/float(len_data)\n",
        "    metric=t_metric/float(len_data)\n",
        "\n",
        "    return loss, metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ao6M3dBXMcha"
      },
      "outputs": [],
      "source": [
        "def train_val(model, params, verbose=False):\n",
        "\n",
        "    # Get the parameters\n",
        "    epochs=params[\"epochs\"]\n",
        "    loss_func=params[\"f_loss\"]\n",
        "    opt=params[\"optimiser\"]\n",
        "    train_dl=params[\"train\"]\n",
        "    val_dl=params[\"val\"]\n",
        "    lr_scheduler=params[\"lr_change\"]\n",
        "    weight_path=params[\"weight_path\"]\n",
        "\n",
        "    loss_history={\"train\": [],\"val\": []}\n",
        "    metric_history={\"train\": [],\"val\": []}\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_loss=float('inf')\n",
        "\n",
        "\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "\n",
        "        # Get the Learning Rate\n",
        "        current_lr = get_lr(opt)\n",
        "        if(verbose):\n",
        "            print('Epoch {}/{}, current lr={}'.format(epoch, epochs - 1, current_lr))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        model.train()\n",
        "        train_loss, train_metric = loss_epoch(model,loss_func,train_dl,opt)\n",
        "\n",
        "        loss_history[\"train\"].append(train_loss)\n",
        "        metric_history[\"train\"].append(train_metric)\n",
        "\n",
        "\n",
        "# Evaluate Model Process\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_loss, val_metric = loss_epoch(model,loss_func,val_dl)\n",
        "\n",
        "        if(val_loss < best_loss):\n",
        "            best_loss = val_loss\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "            torch.save(model.state_dict(), weight_path)\n",
        "            if(verbose):\n",
        "                print(\"Copied best model weights!\")\n",
        "\n",
        "        loss_history[\"val\"].append(val_loss)\n",
        "        metric_history[\"val\"].append(val_metric)\n",
        "\n",
        "        lr_scheduler.step(val_loss)\n",
        "        if current_lr != get_lr(opt):\n",
        "            if(verbose):\n",
        "                print(\"Loading best model weights!\")\n",
        "            model.load_state_dict(best_model_wts)\n",
        "\n",
        "        if(verbose):\n",
        "            print(f\"train loss: {train_loss:.6f}, dev loss: {val_loss:.6f}, accuracy: {100*val_metric:.2f}\")\n",
        "            print(\"-\"*10)\n",
        "\n",
        "    model.load_state_dict(best_model_wts)\n",
        "\n",
        "    return model, loss_history, metric_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353,
          "referenced_widgets": [
            "24ebeb802a0942b886315c9119c7cd9a",
            "539dd373dba6412581341f56d2cf7e31",
            "c2991ae6545a48dfbe74862221b82eb6",
            "b05560207b0040f397700898b9c0eded",
            "8947ca3debe8409ea73bee1c2e19f8cf",
            "375106420da547418ffa3be4cbeaab60",
            "1b401a741d9e4548b02c8df4439f175a",
            "8a86d302f0464526a804101d931da40b",
            "59b6f5b23f354afe8bf8ead4355f15e0",
            "215fb254742147c8a782acbada2d9d58",
            "b3de20aac70f4b10b5341733afcea1e6"
          ]
        },
        "id": "BAfKhTd4bV7A",
        "outputId": "5f31466a-69ce-44e4-f5c7-ca01715d8602"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/80 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "24ebeb802a0942b886315c9119c7cd9a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-82ee321f94ca>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# train and validate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_hist_m\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetric_hist_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_val\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResNet_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparams_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-39-575b53c8093c>\u001b[0m in \u001b[0;36mtrain_val\u001b[0;34m(model, params, verbose)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mloss_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-f9be6a08ddd8>\u001b[0m in \u001b[0;36mloss_epoch\u001b[0;34m(model, loss_func, dataset_dl, opt)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0myb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mloss_b\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetric_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mrun_loss\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mloss_b\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-f9be6a08ddd8>\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(loss_func, output, target, opt)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# get loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Get Output Class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mmetric_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# get performance metric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "params_train={\n",
        " \"train\": train_loader,\"val\": val_loader,\n",
        " \"epochs\": 80,\n",
        " \"optimiser\": optim.Adam(ResNet_model.parameters(),lr=1e-3),\n",
        " \"lr_change\": ReduceLROnPlateau(opt, mode='min',factor=0.5, patience=20,verbose=1),\n",
        " \"f_loss\": nn.CrossEntropyLoss(),\n",
        " \"weight_path\": \"weights_run3.pt\",\n",
        "}\n",
        "\n",
        "# train and validate the model\n",
        "model,loss_hist_m,metric_hist_m = train_val(ResNet_model,params_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3L6VmJt2EBq4"
      },
      "source": [
        "## Generate Convergance Plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRRJ2PmrbiSX"
      },
      "outputs": [],
      "source": [
        "epochs=params_train[\"epochs\"]\n",
        "fig,ax = plt.subplots(1,2,figsize=(12,5))\n",
        "\n",
        "sns.lineplot(x=[*range(1,epochs+1)],y=loss_hist_m[\"train\"],ax=ax[0],label='loss_hist[\"train\"]')\n",
        "sns.lineplot(x=[*range(1,epochs+1)],y=loss_hist_m[\"val\"],ax=ax[0],label='loss_hist[\"val\"]')\n",
        "sns.lineplot(x=[*range(1,epochs+1)],y=metric_hist_m[\"train\"],ax=ax[1],label='Acc_hist[\"train\"]')\n",
        "sns.lineplot(x=[*range(1,epochs+1)],y=metric_hist_m[\"val\"],ax=ax[1],label='Acc_hist[\"val\"]')\n",
        "\n",
        "plt.savefig(\"ResNet_model_convergence_hist_plot_run3.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-T2WAGbOFLRJ"
      },
      "source": [
        "## Classification Report for Training Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "NExsdQlKfWVj"
      },
      "outputs": [],
      "source": [
        "def ture_and_pred_data(val_loader, model):\n",
        "    i = 0\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    for images, labels in val_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.numpy()\n",
        "        outputs = model(images)\n",
        "        _, pred = torch.max(outputs.data, 1)\n",
        "        pred = pred.detach().cpu().numpy()\n",
        "\n",
        "        y_true = np.append(y_true, labels)\n",
        "        y_pred = np.append(y_pred, pred)\n",
        "\n",
        "    return y_true, y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xr-hW-1LfZdE"
      },
      "outputs": [],
      "source": [
        "# Classification Report for Model based on Train Set\n",
        "\n",
        "y_true, y_pred = ture_and_pred_data(train_loader, ResNet_model)\n",
        "print(classification_report(y_true, y_pred), '\\n\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xd3JNGfFVOc"
      },
      "source": [
        "## Classification Report for Validation Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhEySLRifbe1"
      },
      "outputs": [],
      "source": [
        " # Classification Report for Model based on Validation Set\n",
        "\n",
        "y_true, y_pred = ture_and_pred_data(val_loader, ResNet_model)\n",
        "print(classification_report(y_true, y_pred), '\\n\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBhvild2FgTX"
      },
      "source": [
        "## Save the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-K_ga05f5Nk"
      },
      "outputs": [],
      "source": [
        "torch.save(ResNet_model, \"ResNet_Model_run3.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMuwjumbFdUc"
      },
      "source": [
        "## Evaluate model on Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "CX6xrRUPgBcQ"
      },
      "outputs": [],
      "source": [
        "# Load the pretrained model\n",
        "model = torch.load(\"/content/resNet_model3.pt\") #change to your file path\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This cell is repeated for running the pretrained model and making the predictions on the test set\n",
        "def ture_and_pred_data(val_loader, model):\n",
        "    i = 0\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    for images, labels in val_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.numpy()\n",
        "        outputs = model(images)\n",
        "        _, pred = torch.max(outputs.data, 1)\n",
        "        pred = pred.detach().cpu().numpy()\n",
        "\n",
        "        y_true = np.append(y_true, labels)\n",
        "        y_pred = np.append(y_pred, pred)\n",
        "\n",
        "    return y_true, y_pred"
      ],
      "metadata": {
        "id": "nt0YMV2Buugs"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "U0MSosljF8Ow",
        "outputId": "0ff8f4af-0e53-4e70-ed5a-093816bf7616",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: 3\n",
            "Predicted class: 1\n",
            "Predicted class: 2\n",
            "Predicted class: 1\n",
            "Predicted class: 2\n",
            "Predicted class: 2\n",
            "Predicted class: 2\n",
            "Predicted class: 0\n",
            "Predicted class: 1\n",
            "Predicted class: 4\n",
            "Predicted class: 2\n",
            "Predicted class: 2\n",
            "Predicted class: 1\n",
            "Predicted class: 2\n",
            "Predicted class: 2\n",
            "Predicted class: 2\n",
            "Predicted class: 1\n",
            "Predicted class: 1\n",
            "Predicted class: 2\n",
            "Predicted class: 1\n",
            "Predicted class: 1\n",
            "Predicted class: 3\n",
            "Predicted class: 2\n",
            "Predicted class: 1\n",
            "Predicted class: 2\n",
            "Predicted class: 2\n",
            "Predicted class: 2\n",
            "Predicted class: 1\n",
            "Predicted class: 2\n",
            "Predicted class: 2\n",
            "Predicted class: 2\n",
            "Predicted class: 1\n",
            "Predicted class: 2\n",
            "Predicted class: 0\n",
            "Predicted class: 2\n",
            "Predicted class: 2\n",
            "Predicted class: 1\n",
            "Predicted class: 3\n",
            "Predicted class: 1\n",
            "Predicted class: 2\n",
            "Predicted class: 2\n",
            "Predicted class: 0\n",
            "Predicted class: 2\n",
            "Predicted class: 1\n",
            "Predicted class: 2\n",
            "Predicted class: 2\n",
            "Predicted class: 0\n",
            "Predicted class: 2\n",
            "Predicted class: 2\n",
            "Predicted class: 0\n",
            "Predicted class: 2\n",
            "Predicted class: 2\n",
            "Predicted class: 2\n",
            "Predicted class: 2\n",
            "Predicted class: 2\n",
            "Predicted class: 2\n",
            "Predicted class: 2\n",
            "Predicted class: 2\n",
            "Predicted class: 2\n",
            "Predicted class: 2\n",
            "Predicted class: 2\n",
            "Predicted class: 2\n",
            "Predicted class: 1\n",
            "Predicted class: 1\n",
            "Predicted class: 2\n",
            "Predicted class: 1\n",
            "Predicted class: 2\n",
            "Predicted class: 2\n",
            "Predicted class: 2\n",
            "Predicted class: 1\n",
            "Predicted class: 0\n",
            "Predicted class: 1\n",
            "Predicted class: 2\n",
            "Predicted class: 1\n",
            "Predicted class: 2\n",
            "Predicted class: 0\n",
            "Predicted class: 2\n",
            "Predicted class: 1\n",
            "Predicted class: 1\n",
            "Predicted class: 2\n",
            "Predicted class: 2\n",
            "Predicted class: 1\n",
            "Predicted class: 1\n",
            "Predicted class: 1\n",
            "Predicted class: 2\n",
            "Predicted class: 0\n",
            "Predicted class: 1\n",
            "Predicted class: 2\n",
            "Predicted class: 0\n",
            "Predicted class: 2\n",
            "Predicted class: 1\n",
            "Predicted class: 2\n",
            "Predicted class: 2\n",
            "Predicted class: 1\n",
            "Predicted class: 1\n",
            "Predicted class: 2\n",
            "Predicted class: 2\n",
            "Predicted class: 2\n",
            "Predicted class: 1\n",
            "Predicted class: 1\n",
            "Predicted class: 1\n",
            "Predicted class: 2\n",
            "Predicted class: 1\n",
            "Predicted class: 2\n",
            "Predicted class: 1\n",
            "Predicted class: 1\n",
            "Predicted class: 1\n",
            "Predicted class: 0\n",
            "Predicted class: 2\n",
            "Predicted class: 2\n",
            "Predicted class: 2\n",
            "Predicted class: 1\n",
            "Predicted class: 1\n",
            "Predicted class: 2\n",
            "Predicted class: 0\n",
            "Predicted class: 3\n",
            "Predicted class: 1\n",
            "Predicted class: 0\n",
            "Predicted class: 1\n",
            "Predicted class: 2\n",
            "Predicted class: 2\n",
            "Predicted class: 1\n",
            "Predicted class: 1\n",
            "Predicted class: 1\n",
            "Predicted class: 1\n",
            "Predicted class: 0\n",
            "Predicted class: 2\n",
            "Predicted class: 1\n",
            "Predicted class: 3\n",
            "Predicted class: 2\n",
            "Predicted class: 1\n",
            "Predicted class: 2\n",
            "Predicted class: 4\n",
            "Predicted class: 2\n",
            "Predicted class: 2\n",
            "Predicted class: 2\n",
            "Predicted class: 2\n",
            "Predicted class: 2\n",
            "Predicted class: 1\n",
            "Predicted class: 1\n",
            "Predicted class: 3\n",
            "Predicted class: 1\n",
            "Predicted class: 1\n",
            "Predicted class: 2\n",
            "Predicted class: 2\n",
            "Predicted class: 2\n",
            "Predicted class: 2\n",
            "Predicted class: 1\n",
            "Predicted class: 1\n",
            "Predicted class: 2\n",
            "Predicted class: 1\n",
            "Predicted class: 1\n",
            "Predicted class: 2\n",
            "Predicted class: 1\n",
            "Predicted class: 2\n",
            "Predicted class: 2\n",
            "Predicted class: 2\n",
            "Predicted class: 2\n",
            "Predicted class: 0\n",
            "Predicted class: 0\n",
            "Predicted class: 2\n",
            "Predicted class: 1\n",
            "Predicted class: 1\n",
            "Predicted class: 2\n",
            "Predicted class: 2\n",
            "Predicted class: 2\n",
            "Predicted class: 2\n",
            "Predicted class: 2\n",
            "Predicted class: 1\n",
            "Predicted class: 2\n",
            "Predicted class: 0\n",
            "Predicted class: 2\n",
            "Predicted class: 1\n",
            "Predicted class: 1\n",
            "Predicted class: 2\n",
            "Predicted class: 1\n",
            "Predicted class: 1\n",
            "Predicted class: 2\n",
            "Predicted class: 2\n",
            "Predicted class: 2\n",
            "Predicted class: 2\n",
            "Predicted class: 0\n",
            "Predicted class: 1\n",
            "Predicted class: 1\n",
            "Predicted class: 1\n",
            "Predicted class: 2\n",
            "Predicted class: 1\n",
            "Predicted class: 2\n",
            "Predicted class: 1\n",
            "Predicted class: 0\n",
            "Predicted class: 1\n",
            "Predicted class: 2\n",
            "Predicted class: 1\n",
            "Predicted class: 2\n",
            "Predicted class: 1\n",
            "Predicted class: 2\n",
            "Predicted class: 2\n",
            "Predicted class: 3\n",
            "Predicted class: 2\n",
            "Predicted class: 2\n",
            "Predicted class: 0\n",
            "Predicted class: 1\n",
            "Predicted class: 2\n",
            "Predicted class: 1\n",
            "Predicted class: 2\n",
            "Predicted class: 0\n",
            "Predicted class: 2\n",
            "Predicted class: 0\n",
            "Predicted class: 2\n",
            "Predicted class: 1\n",
            "Predicted class: 1\n",
            "Predicted class: 2\n",
            "Predicted class: 2\n",
            "Predicted class: 2\n",
            "Predicted class: 1\n",
            "Predicted class: 1\n",
            "Predicted class: 0\n",
            "Predicted class: 2\n",
            "Predicted class: 0\n",
            "Predicted class: 2\n",
            "Predicted class: 1\n",
            "Predicted class: 2\n",
            "Predicted class: 2\n",
            "Predicted class: 2\n",
            "Predicted class: 2\n",
            "Predicted class: 2\n",
            "Predicted class: 1\n",
            "Predicted class: 2\n",
            "Predicted class: 1\n",
            "Predicted class: 2\n",
            "Predicted class: 0\n"
          ]
        }
      ],
      "source": [
        "# Iterate over the test loader for prediction\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, _ in test_loader:\n",
        "\n",
        "        images = images.to(device)\n",
        "        output = model(images)\n",
        "        probabilities = torch.softmax(output, dim=1)\n",
        "        predicted_classes = torch.argmax(probabilities, dim=1)\n",
        "\n",
        "        for predicted_class in predicted_classes:\n",
        "            print(\"Predicted class:\", predicted_class.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "mo6CHBgvgXCz",
        "outputId": "9ad35bff-c3ed-4812-a5f6-68786f67f969",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.48      0.55      0.51        20\n",
            "         1.0       0.66      0.82      0.73        65\n",
            "         2.0       0.96      0.97      0.96       118\n",
            "         3.0       0.50      0.15      0.23        20\n",
            "         4.0       0.33      0.12      0.18         8\n",
            "\n",
            "    accuracy                           0.79       231\n",
            "   macro avg       0.59      0.52      0.52       231\n",
            "weighted avg       0.77      0.79      0.77       231\n",
            " \n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "## Classification Report for Model based on Test set\n",
        "\n",
        "y_true, y_pred = ture_and_pred_data(test_loader, model)\n",
        "print(classification_report(y_true, y_pred), '\\n\\n')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "24ebeb802a0942b886315c9119c7cd9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_539dd373dba6412581341f56d2cf7e31",
              "IPY_MODEL_c2991ae6545a48dfbe74862221b82eb6",
              "IPY_MODEL_b05560207b0040f397700898b9c0eded"
            ],
            "layout": "IPY_MODEL_8947ca3debe8409ea73bee1c2e19f8cf"
          }
        },
        "539dd373dba6412581341f56d2cf7e31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_375106420da547418ffa3be4cbeaab60",
            "placeholder": "​",
            "style": "IPY_MODEL_1b401a741d9e4548b02c8df4439f175a",
            "value": " 76%"
          }
        },
        "c2991ae6545a48dfbe74862221b82eb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a86d302f0464526a804101d931da40b",
            "max": 80,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_59b6f5b23f354afe8bf8ead4355f15e0",
            "value": 61
          }
        },
        "b05560207b0040f397700898b9c0eded": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_215fb254742147c8a782acbada2d9d58",
            "placeholder": "​",
            "style": "IPY_MODEL_b3de20aac70f4b10b5341733afcea1e6",
            "value": " 61/80 [16:04&lt;04:57, 15.64s/it]"
          }
        },
        "8947ca3debe8409ea73bee1c2e19f8cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "375106420da547418ffa3be4cbeaab60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b401a741d9e4548b02c8df4439f175a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a86d302f0464526a804101d931da40b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59b6f5b23f354afe8bf8ead4355f15e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "215fb254742147c8a782acbada2d9d58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3de20aac70f4b10b5341733afcea1e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}